2025-10-12 03:23:41,479 - Log file for this run: C:\ai8x\ai8x-training\logs\2025.10.12-032341\2025.10.12-032341.log
2025-10-12 03:23:45,536 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-10-12 03:23:45,536 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2025-10-12 03:23:46,209 - Dataset sizes:
	training=28818
	validation=3202
	test=2023
2025-10-12 03:23:46,209 - Reading compression schedule from: policies/schedule-catsdogs.yaml
2025-10-12 03:23:46,226 - 

2025-10-12 03:23:46,227 - Training epoch: 28818 samples (256 per mini-batch)
2025-10-12 03:30:00,349 - Epoch: [0][  113/  113]    Overall Loss 0.653223    Objective Loss 0.653223    Top1 62.935323    LR 0.001000    Time 3.310694    
2025-10-12 03:30:01,595 - --- validate (epoch=0)-----------
2025-10-12 03:30:01,595 - 3202 samples (256 per mini-batch)
2025-10-12 03:30:23,250 - Epoch: [0][   13/   13]    Loss 0.599102    Top1 66.833229    
2025-10-12 03:30:23,887 - ==> Top1: 66.833    Loss: 0.599

2025-10-12 03:30:23,887 - ==> Confusion:
[[ 916  658]
 [ 404 1224]]

2025-10-12 03:30:24,050 - ==> Best [Top1: 66.833   Sparsity:0.00   Params: 57776 on epoch: 0]
2025-10-12 03:30:24,050 - Saving checkpoint to: logs\2025.10.12-032341\checkpoint.pth.tar
2025-10-12 03:30:24,088 - 

2025-10-12 03:30:24,088 - Training epoch: 28818 samples (256 per mini-batch)
2025-10-12 03:35:48,267 - Epoch: [1][  113/  113]    Overall Loss 0.571895    Objective Loss 0.571895    Top1 71.144279    LR 0.001000    Time 2.868838    
2025-10-12 03:35:49,494 - --- validate (epoch=1)-----------
2025-10-12 03:35:49,503 - 3202 samples (256 per mini-batch)
2025-10-12 03:36:11,457 - Epoch: [1][   13/   13]    Loss 0.537072    Top1 73.141786    
2025-10-12 03:36:12,036 - ==> Top1: 73.142    Loss: 0.537

2025-10-12 03:36:12,046 - ==> Confusion:
[[1049  525]
 [ 335 1293]]

2025-10-12 03:36:12,156 - ==> Best [Top1: 73.142   Sparsity:0.00   Params: 57776 on epoch: 1]
2025-10-12 03:36:12,156 - Saving checkpoint to: logs\2025.10.12-032341\checkpoint.pth.tar
2025-10-12 03:36:12,182 - 

2025-10-12 03:36:12,182 - Training epoch: 28818 samples (256 per mini-batch)
2025-10-12 03:41:39,893 - Epoch: [2][  113/  113]    Overall Loss 0.512212    Objective Loss 0.512212    Top1 77.860697    LR 0.001000    Time 2.900094    
2025-10-12 03:41:41,106 - --- validate (epoch=2)-----------
2025-10-12 03:41:41,116 - 3202 samples (256 per mini-batch)
2025-10-12 03:42:01,862 - Epoch: [2][   13/   13]    Loss 0.485713    Top1 76.764522    
2025-10-12 03:42:02,485 - ==> Top1: 76.765    Loss: 0.486

2025-10-12 03:42:02,485 - ==> Confusion:
[[1163  411]
 [ 333 1295]]

2025-10-12 03:42:02,604 - ==> Best [Top1: 76.765   Sparsity:0.00   Params: 57776 on epoch: 2]
2025-10-12 03:42:02,605 - Saving checkpoint to: logs\2025.10.12-032341\checkpoint.pth.tar
2025-10-12 03:42:02,628 - 

2025-10-12 03:42:02,628 - Training epoch: 28818 samples (256 per mini-batch)
2025-10-12 03:47:26,705 - Epoch: [3][  113/  113]    Overall Loss 0.468988    Objective Loss 0.468988    Top1 77.860697    LR 0.001000    Time 2.867842    
2025-10-12 03:47:27,954 - --- validate (epoch=3)-----------
2025-10-12 03:47:27,954 - 3202 samples (256 per mini-batch)
2025-10-12 03:47:48,730 - Epoch: [3][   13/   13]    Loss 0.469766    Top1 77.514054    
2025-10-12 03:47:49,386 - ==> Top1: 77.514    Loss: 0.470

2025-10-12 03:47:49,386 - ==> Confusion:
[[1212  362]
 [ 358 1270]]

2025-10-12 03:47:49,501 - ==> Best [Top1: 77.514   Sparsity:0.00   Params: 57776 on epoch: 3]
2025-10-12 03:47:49,502 - Saving checkpoint to: logs\2025.10.12-032341\checkpoint.pth.tar
2025-10-12 03:47:49,517 - 

2025-10-12 03:47:49,517 - Training epoch: 28818 samples (256 per mini-batch)
2025-10-12 03:53:13,623 - Epoch: [4][  113/  113]    Overall Loss 0.430377    Objective Loss 0.430377    Top1 79.104478    LR 0.001000    Time 2.868195    
2025-10-12 03:53:14,846 - --- validate (epoch=4)-----------
2025-10-12 03:53:14,856 - 3202 samples (256 per mini-batch)
2025-10-12 03:53:35,951 - Epoch: [4][   13/   13]    Loss 0.460576    Top1 77.795128    
2025-10-12 03:53:36,521 - ==> Top1: 77.795    Loss: 0.461

2025-10-12 03:53:36,521 - ==> Confusion:
[[1391  183]
 [ 528 1100]]

2025-10-12 03:53:36,633 - ==> Best [Top1: 77.795   Sparsity:0.00   Params: 57776 on epoch: 4]
2025-10-12 03:53:36,633 - Saving checkpoint to: logs\2025.10.12-032341\checkpoint.pth.tar
2025-10-12 03:53:36,657 - --- test ---------------------
2025-10-12 03:53:36,658 - 2023 samples (256 per mini-batch)
2025-10-12 03:53:59,443 - Test: [    8/    8]    Loss 0.444012    Top1 80.177954    
2025-10-12 03:53:59,443 - ==> Top1: 80.178    Loss: 0.444

2025-10-12 03:53:59,443 - ==> Confusion:
[[907 104]
 [297 715]]

2025-10-12 03:53:59,453 - 
2025-10-12 03:53:59,453 - Log file for this run: C:\ai8x\ai8x-training\logs\2025.10.12-032341\2025.10.12-032341.log
